
<!doctype html>
<html>
<head>
    <meta charset="utf-8">

    <title>Antoine Jardin's Blog</title>
    <link rel="stylesheet" type="text/css" href="style.css">
</head>



<body>

    <div class="nav">
        <ul>
        <li><a href="http://antoinejardin.github.io/site/">Home</a>
        <li><a href="#">Data</a>
	<li><a href="http://spire.sciencespo.fr/hdl:/2441/6mnmm960se8udqhl52ulaad5gu">Research</a>
	<li><a href="http://antoinejardin.github.io/site/teaching.html">Teaching</a>
        <li><a href="#">Papers</a>
        <li><a href="#">Archives</a>
        <li><a href="#">Varia</a>
        <li><a href="http://antoinejardin.github.io/site/about.html">About Me</a>
    </ul>
	</div>

    <div class="content">


<p>Choosing a modelling technique</p>

<pre>
	
Stata Manual makes the following point : 

**************************************************************************************
Remarks on using sampling weights

    Sampling weights are treated differently in multilevel models than they are
    in standard models such as OLS regression.  In a multilevel model,
    observation-level weights are not indicative of overall inclusion.
    Instead, they indicate inclusion conditional on the corresponding cluster
    being included at the next highest-level of sampling.

    For example, if you include only observation-level weights in a two-level
    model, mixed will assume sampling with equal probabilities at level two,
    and this may or may not be what you intended.  If the sampling at level two
    is weighted, then including only level-one weights can lead to biased
    results even if weighting at level two has been incorporated into the
    level-one weight variable.  For example, it is a common practice to
    multiply conditional weights from multiple levels into one overall weight.
    By contrast, weighted multilevel analysis requires the component weights
    from each level of sampling.

    Even if you specify sampling weights at all model levels, the scale of
    sampling weights at lower levels can affect your estimated parameters in a
    multilevel model.  That is, not only do the relative sizes of the weights
    at lower levels matter, the scale of these weights matters also.  To deal
    with this, mixed has the pwscale() option for rescaling weights in
    two-level models; see above for more information on pwscale().  Three
    scaling methods are offered, with each method known to perform well under
    certain data situations and posited models.

    In general, exercise caution when using sampling weights with mixed; see 
    Survey data in [ME] mixed for more information.
**************************************************************************************

Hence it seems better to only pick OLS models with several interactions

[#] Ologit and Oprobit Models

1. ologit  roma c.educ##i.country c.age##i.country c.ethno##i.country i.contact##i.country i.gender##i.country [iw=w22]
2. oprobit roma c.educ##i.country c.age##i.country c.ethno##i.country i.contact##i.country i.gender##i.country [iw=w22]

	[*] Postestimation

1. predict plo1 plo2 plo3 plo4 plo5 plo6 plo7 plo8 plo9 plo10
2. predict ppro1 ppro2 ppro3 ppro4 ppro5 ppro6 ppro7 ppro8 ppro9 ppro10

--- We compute one predicted probability for each outcomes of the dependant variable : roma scaled in 1/10 
--- ppro(n) are predicted probabilities for the probit model 
--- plo(n) are predicted probabilities for the probit model 

	[*] Predictive Margins
	
--- To estimate predictive margins we need to specify the outcome considered

margins,  predict(outcome(1)) atmeans
margins,  predict(outcome(2)) atmeans
margins,  predict(outcome(3)) atmeans
margins,  predict(outcome(4)) atmeans
margins,  predict(outcome(5)) atmeans
margins,  predict(outcome(6)) atmeans
margins,  predict(outcome(7)) atmeans
margins,  predict(outcome(8)) atmeans
margins,  predict(outcome(9)) atmeans
margins,  predict(outcome(10)) atmeans

--- Of course we can define other values for each independant variable 

margins, at (age = (20 (10) 80))  predict(outcome(1))
margins, at (ethno = (0 (0.5) 10))  predict(outcome(4))
margins, at (contact = (0 1))  predict(outcome(8))

etc ...


[#] GOlogit and GOprobit Models

GOlogit and GOprobit are General Ordered Logit and General Ordered Probit models

They represent an intermediate step between Ordinal Models and Mixed Multilevel Models.

- Ordinal Models considers that the function of the model applies in the same way from outcome #1 to outcome #2 than from outcome #3 to outcome #4
- This may be the case but it's a rare scenario in the real world.

- On the other hand, Mixed Multilevel Models do not consider any kind of order among the dependant variable values.
- Hence they model each outcome with no order constraint at all
- This make those models (a) difficult to estimate in terms of computation time (b) less parcimonious (c) harder to interpret and (d) it's harder to extract predicted values and predictive margins.

- GOlogit and GOprobit on the other hand (a) DO consider that the dependant variable values are ordered (b) DO NOT consider that the function is the same when moving from outcome #1 to outcome #2 to outcome #3

[ According to Stata 13 Manual ]

**********************************************************************

   gologit2 is a user-written program that estimates generalized ordered logit models for ordinal dependent variables. The actual values taken on by the dependent variable are irrelevant except that larger values are assumed to
    correspond to "higher" outcomes. Up to 20 outcomes are allowed. gologit2 is inspired by Vincent Fu's gologit program and is backward compatible with it (and with gologit29) but offers several additional powerful options,
    including support for factor variables and complex survey data estimation.

    A major strength of gologit2 is that it can also estimate three special cases of the generalized model: the proportional odds/parallel lines model, the partial proportional odds model, and the logistic regression model. Hence,
    gologit2 can estimate models that are less restrictive than the proportional odds /parallel lines models estimated by ologit (whose assumptions are often violated) but more parsimonious and interpretable than those estimated by a
    non-ordinal method, such as multinomial logistic regression (i.e. mlogit). The autofit option greatly simplifies the process of identifying partial proportional odds models that fit the data.

**********************************************************************
    
	[*] Other Link Functions

[ From Stata Manual ]

**********************************************************************

    link(logit/probit/cloglog/loglog/cauchit) specifies the link function to be used.  The legal values are link(logit), link(probit), link(cloglog), link(loglog), and link(cauchit), which can be abbreviated as link(l), link(p),
        link(c), link(ll) and link(ca). link(logit) is the default if the option is omitted.

        The following advice is adapted from Norusis (2005, p. 84):  Probit and logit models are reasonable choices when the changes in the cumulative probabilities are gradual. If there are abrupt changes, other link functions
        should be used. The log-log link may be a good model when the cumulative probabilities increase from 0 fairly slowly and then rapidly approach 1. If the opposite is true, namely that the cumulative probability for lower
        scores is high and the approach to 1 is slow, the complementary log-log link may describe the data. The cauchit distribution has tails that are bigger than the normal distributionâ€™s, hence the cauchit link may be useful when
        you have more extreme values in either direction.

**********************************************************************

</pre>

<p>Romaphobia modeling<p>

<pre>
library(ordinal)
library(dplyr)
library(foreign)
library(lme4)
</pre>
<p></p>
<pre>
roma <- read.csv("~/roma.csv")
</pre>
<p></p>

<pre>
rom <- select(roma, -(X.2:X))
</pre>
<p></p>

<pre>
rom$contact <- as.factor(rom$contact)
</pre>
<p></p>

<pre>
fm1 <- clm(contact ~ gender + educ + age + ethno + place + relig + country, data=rom, Hess = TRUE, link="logit")

fm1p <- clm(contact ~ gender + educ + age + ethno + place + relig + country, data=rom, Hess = TRUE, link="logit", weights=pond)
</pre>
<p></p>

<pre>
rom$roma <- as.factor(rom$roma)
</pre>
<p></p>

<pre>
fm2 <- clm(roma ~ gender + educ + age + ethno + place + relig + contact + country, data=rom, Hess = TRUE, link="probit")

fm2p <- clm(roma ~ gender + educ + age + ethno + place + relig + contact + country, data=rom, Hess = TRUE, link="probit", weights=pond)
</pre>
<p></p>

<pre>
summary(fm1)
summary(fm1p)

summary(fm2)
summary(fm2p)
</pre>
<p></p>

<pre>
fm1r <- clmm(contact ~ gender + educ + age + ethno + place + relig + (1 | country), data=rom, Hess = TRUE, link="logit")
fm1rp <- clmm(contact ~ gender + educ + age + ethno + place + relig + (1 | country), data=rom, Hess = TRUE, link="logit", weights=pond)
</pre>
<p></p>

<pre>
fm2rp <- clmm(roma ~ gender + educ + age + ethno + place + relig + contact + ( 1 | country) , data=rom, Hess = TRUE, link="probit", weights=pond)
</pre>
<p></p>

<pre>
fm3p <- clm(roma ~ contact*country , data=rom, Hess = TRUE, link="probit", weights=pond)
</pre>
<p></p>

<pre>
summary(fm3p)

fit.fm3p <- fitted(fm3p)

summary(fm1p)
summary(fm1rp)
summary(fm2p)
summary(fm1p)
summary(fm2)
</pre>
<p></p>

<pre>
fm4p <- clmm(roma ~ gender + (1 + contact | country) , data=rom, Hess = TRUE, link="probit", weights=pond)

summary(fm4p)
ranef(fm4p)
</pre>
<p></p>

<pre>
doc <- as.data.frame(ranef(fm4p))

View(doc)
</pre>
<p></p>

<pre>
fm5p <- clmm(roma ~ gender + ethno + contact + (1 + contact | country) , data=rom, Hess = TRUE, link="probit", weights=pond)

fm6p <- clmm(roma ~ gender + ethno + contact + (1 + contact + ethno | country) , data=rom, Hess = TRUE, link="probit", weights=pond)

fm7p <- clmm(roma ~ gender + ethno + (1 + contact | country) , data=rom, Hess = TRUE, link="probit", weights=pond)
</pre>
<p></p>

<pre>
summary(fm7p)
ranef(fm7p)

summary(fm6p)
ranef(fm6p)
</pre>
<p></p>

<pre>
fm8p <- clmm(roma ~ gender + ethno + educ + (1 + contact | country) , data=rom, Hess = TRUE, link="probit", weights=pond)
</pre>
<p></p>

<pre>
summary(fm8p)
ranef(fm8p)
ran8 <- as.data.frame(ranef(fm8p))

rom$f.ethno <- as.factor(rom$ethno)
</pre>
<p></p>

<pre>
summary(fm8p)
pred8 <- fitted(fm8p)
res8 <- cbind(pred8, rom)
head(res8)
</pre>
<p></p>

<pre>
write.csv(res8, file="~/res8.csv")
write.dta(res8, file="~/res8.dta")
</pre>
<p></p>

<pre>
fm9p <- lmer(roma ~ gender + ethno + educ + (1 + contact | country) , data=rom, weights=pond)
</pre>
<p></p>

<pre>
summary(fm9p)
ranef(fm9p)
pred9 <- fitted(fm9p)
base9 <- fm9p@frame
res9 <- cbind(base9, pred9)
</pre>
<p></p>

<pre>
write.dta(res9, file="~/res.dta")
write.dta(res9, file="~/res9.dta")
</pre>
<p></p>

<pre>
savehistory("~/tommaso_clm.Rhistory")
</pre>
<p></p>

</div>

<div class="footer">
Made in HTML and CSS - Antoine Jardin - 2015
<div>


</body>
</html>

